{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23bf6aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "cab270f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f12b5586d40>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoFeatureExtractor, AutoModel, AutoTokenizer\n",
    "import librosa\n",
    "import torch\n",
    "from glob import glob\n",
    "from jiwer import cer\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e636abab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "ds = load_dataset(\"malaysia-ai/common_voice_17_0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "33660bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = ds['test'].to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3bde7331",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(533642, 14)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf7d78d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4abbc7ebb44041d8b2d303bd0036eda1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "preprocessor_config.json:   0%|          | 0.00/357 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d2feb032f3564768b5d1b5ed5fc9414e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c4f1d46958684120af229b92bd518496",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "whispervq_conv.py: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A new version of the following files was downloaded from https://huggingface.co/mesolitica/whisper-conv-VQ-32k-large-v3-turbo:\n",
      "- whispervq_conv.py\n",
      ". Make sure to double-check they do not contain any added malicious code. To avoid downloading new versions of the code file, you can pin a revision.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9124c3a22ac746c79eab0bd48a705c69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/3.40G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "111f6a8f40c64ed3840806782e9ab6bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c80521ca166445dbd7c2fec8550ed8a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25db2a29437d4804b296d894362f2647",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96c4a9261af642a5aadb070d9a4975f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44b0120048974c9f95f9df9753bd8345",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a740ae35d4a34f1c9b21b5e4e4c751c7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "normalizer.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a2d14b833fa8445199bacf1da6451526",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "13de565f286f4725a99891d8bebf2bcd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json: 0.00B [00:00, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_id = \"mesolitica/whisper-conv-VQ-32k-large-v3-turbo\"\n",
    "feature_extractor = AutoFeatureExtractor.from_pretrained(model_id)\n",
    "model = AutoModel.from_pretrained(model_id, trust_remote_code = True, torch_dtype = 'auto').cuda()\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f68e4a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir evaluate-whisper-conv-VQ-32k-large-v3-turbo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4efce9e7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "266821it [1:10:07, 63.41it/s]    \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import json\n",
    "import os\n",
    "\n",
    "template = '<|startoftranscript|><|{locale}|><|transcribe|><|notimestamps|>'\n",
    "\n",
    "for i in tqdm(reversed(range((len(df_test) // 2) * 1, (len(df_test) // 2) * 2, 1))):\n",
    "    \n",
    "    filename = f'evaluate-whisper-conv-VQ-32k-large-v3-turbo/{i}.json'\n",
    "    try:\n",
    "        if os.path.exists(filename):\n",
    "            with open(filename) as fopen:\n",
    "                json.load(fopen)\n",
    "                continue\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    t = df_test['sentence'].iloc[i]\n",
    "\n",
    "    if not isinstance(t, str):\n",
    "        continue\n",
    "\n",
    "    if len(t) < 5:\n",
    "        continue\n",
    "\n",
    "    l = df_test['locale'].iloc[i]\n",
    "\n",
    "    if not isinstance(l, str):\n",
    "        continue\n",
    "\n",
    "    if len(l) < 2:\n",
    "        continue\n",
    "            \n",
    "    y, sr = librosa.load(df_test.iloc[i]['audio_filename'], sr = feature_extractor.sampling_rate)\n",
    "    input_ids = tokenizer(template.replace('{locale}', l), \n",
    "        add_special_tokens = False, return_tensors = 'pt')['input_ids']\n",
    "    features = feature_extractor(\n",
    "        [y], \n",
    "        return_tensors = 'pt', \n",
    "        return_attention_mask = True,\n",
    "        sampling_rate = 16000,\n",
    "    )\n",
    "    features['input_features'] = features['input_features'].cuda()\n",
    "    features['attention_mask'] = features['attention_mask'].cuda()\n",
    "    features['decoder_input_ids'] = input_ids.cuda()\n",
    "    generate_kwargs = dict(\n",
    "        **features,\n",
    "        max_new_tokens=256,\n",
    "        temperature=0.1,\n",
    "        do_sample=True\n",
    "    )\n",
    "    generation_output = model.generate(**generate_kwargs)\n",
    "    decoded = tokenizer.decode(generation_output[0])\n",
    "    with open(filename, 'w') as fopen:\n",
    "        json.dump({'predict': decoded, 'actual': t}, fopen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f134d16f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 532364/532364 [00:31<00:00, 16755.00it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "532364"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "def clean(s):\n",
    "    s = ''.join([c for c in s.lower() if c not in string.punctuation])\n",
    "    return s.strip()\n",
    "\n",
    "languages = defaultdict(list)\n",
    "\n",
    "files = glob('evaluate-whisper-conv-VQ-32k-large-v3-turbo/*')\n",
    "for f in tqdm(files):\n",
    "    with open(f) as fopen:\n",
    "        d = json.load(fopen)\n",
    "    l = d['predict'].split('<|')[2].split('|>')[0]\n",
    "    predict = d['predict'].split('<|notimestamps|>')[1].replace('<|endoftext|>', '')\n",
    "    actual = d['actual']\n",
    "    predict = clean(predict)\n",
    "    actual = clean(actual)\n",
    "    score = cer(actual, predict)\n",
    "    languages[l].append(score)\n",
    "\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5dc4cb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: gl, samples: 9949, CER: 0.179959138002185\n",
      "lang: en, samples: 16379, CER: 0.18379318688291674\n",
      "lang: ar, samples: 10458, CER: 0.442098309275015\n",
      "lang: kab, samples: 14972, CER: 0.5076671557224989\n",
      "lang: ml, samples: 703, CER: 0.7163533887103217\n",
      "lang: kk, samples: 514, CER: 0.4628507980881995\n",
      "lang: ltg, samples: 2904, CER: 0.4205037910930837\n",
      "lang: fr, samples: 16145, CER: 0.1654582834310926\n",
      "lang: de, samples: 16170, CER: 0.1724037776794763\n",
      "lang: fi, samples: 1554, CER: 0.39460069431609057\n",
      "lang: pt, samples: 9432, CER: 0.17848626855907665\n",
      "lang: ia, samples: 1816, CER: 0.15100353821127493\n",
      "lang: eu, samples: 13621, CER: 0.296558713578422\n",
      "lang: ro, samples: 3896, CER: 0.23927959309114133\n",
      "lang: sw, samples: 12086, CER: 0.37654191236655504\n",
      "lang: sv-SE, samples: 5247, CER: 0.30514152709793296\n",
      "lang: ta, samples: 8263, CER: 0.48104527337629344\n",
      "lang: et, samples: 2653, CER: 0.5043074385490827\n",
      "lang: lg, samples: 11902, CER: 0.40869471032709415\n",
      "lang: it, samples: 15154, CER: 0.1520149858391226\n",
      "lang: mhr, samples: 15107, CER: 0.33643170300979874\n",
      "lang: sr, samples: 1539, CER: 0.27426151226637097\n",
      "lang: mr, samples: 1437, CER: 0.6049676171879896\n",
      "lang: ka, samples: 12608, CER: 0.4641408894888927\n",
      "lang: es, samples: 15848, CER: 0.11158011174118186\n",
      "lang: be, samples: 15878, CER: 0.22578637993729334\n",
      "lang: lt, samples: 4753, CER: 0.3434212862030025\n",
      "lang: ca, samples: 16389, CER: 0.1315824165221354\n",
      "lang: eo, samples: 14773, CER: 0.17372091016054594\n",
      "lang: tr, samples: 11235, CER: 0.32994471022721983\n",
      "lang: hu, samples: 11435, CER: 0.3561362381156991\n",
      "lang: ja, samples: 6033, CER: 0.9982833411296135\n",
      "lang: br, samples: 2202, CER: 0.5381746564223735\n",
      "lang: ne-NP, samples: 217, CER: 0.604053957230674\n",
      "lang: uz, samples: 12006, CER: 0.4207017429304853\n",
      "lang: ru, samples: 10184, CER: 0.2849535442232065\n",
      "lang: dv, samples: 2213, CER: 0.6553536784214389\n",
      "lang: tt, samples: 4953, CER: 0.4218519170807958\n",
      "lang: rw, samples: 14797, CER: 0.4474459282723276\n",
      "lang: bn, samples: 9327, CER: 0.6288092560840732\n",
      "lang: ug, samples: 6108, CER: 0.4840831192258846\n",
      "lang: rm-sursilv, samples: 1361, CER: 0.38524075200621666\n",
      "lang: bg, samples: 3201, CER: 0.331453799832877\n",
      "lang: ab, samples: 9108, CER: 0.4736496871597669\n",
      "lang: uk, samples: 9915, CER: 0.2814522916429826\n",
      "lang: mt, samples: 1662, CER: 0.46426521755300143\n",
      "lang: fa, samples: 10292, CER: 0.37443357243073633\n",
      "lang: pl, samples: 9186, CER: 0.31906700327448057\n",
      "lang: bas, samples: 541, CER: 0.48938294627539863\n",
      "lang: nl, samples: 11255, CER: 0.21872580062032035\n",
      "lang: zh-CN, samples: 10335, CER: 0.8210631692844381\n",
      "lang: tok, samples: 2175, CER: 0.17319962128358807\n",
      "lang: ur, samples: 4052, CER: 0.4027290974374358\n",
      "lang: sk, samples: 2593, CER: 0.3354639680359322\n",
      "lang: oc, samples: 254, CER: 0.4043809122006512\n",
      "lang: yue, samples: 2585, CER: 0.7505072448354659\n",
      "lang: mrj, samples: 7102, CER: 0.3983174300047843\n",
      "lang: fy-NL, samples: 3167, CER: 0.4013634703164395\n",
      "lang: cs, samples: 9055, CER: 0.30871198296817226\n",
      "lang: th, samples: 10982, CER: 0.6311950035438857\n",
      "lang: ckb, samples: 5262, CER: 0.41982876859913076\n",
      "lang: mn, samples: 1896, CER: 0.6504788197607608\n",
      "lang: ky, samples: 1604, CER: 0.49966345148800123\n",
      "lang: skr, samples: 1006, CER: 0.5273596174776184\n",
      "lang: hy-AM, samples: 4281, CER: 0.5024096428595386\n",
      "lang: sl, samples: 1242, CER: 0.3072356434149594\n",
      "lang: vi, samples: 1077, CER: 0.5123390332518818\n",
      "lang: hi, samples: 3151, CER: 0.4433347767492109\n",
      "lang: nan-tw, samples: 2317, CER: 0.7641467371011472\n",
      "lang: id, samples: 3633, CER: 0.15998835407786902\n",
      "lang: cy, samples: 5371, CER: 0.46837017267238346\n",
      "lang: yo, samples: 999, CER: 0.7100514992546237\n",
      "lang: sah, samples: 1455, CER: 0.5696483293386966\n",
      "lang: mk, samples: 1097, CER: 0.3633377564531888\n",
      "lang: cv, samples: 1288, CER: 0.5136879769244236\n",
      "lang: myv, samples: 479, CER: 0.4441728174014146\n",
      "lang: da, samples: 2405, CER: 0.3323597890538349\n",
      "lang: lv, samples: 6738, CER: 0.34039794018912223\n",
      "lang: kmr, samples: 3900, CER: 0.4001037734079973\n",
      "lang: tk, samples: 545, CER: 0.5953345982069979\n",
      "lang: nn-NO, samples: 370, CER: 0.38739263901776333\n",
      "lang: ha, samples: 661, CER: 0.3961181418968935\n",
      "lang: he, samples: 260, CER: 0.7651224921633984\n",
      "lang: dyu, samples: 59, CER: 0.5455594488660915\n",
      "lang: gn, samples: 855, CER: 0.5436678887771803\n",
      "lang: lij, samples: 694, CER: 0.4594077375161419\n",
      "lang: hsb, samples: 444, CER: 0.5364972753606619\n",
      "lang: pa-IN, samples: 487, CER: 0.5484373916344527\n",
      "lang: el, samples: 1696, CER: 0.38105151153019773\n",
      "lang: zgh, samples: 159, CER: 1.0\n",
      "lang: as, samples: 551, CER: 0.6162622996828861\n",
      "lang: sq, samples: 472, CER: 0.44938032259231714\n",
      "lang: ko, samples: 338, CER: 1.0\n",
      "lang: ga-IE, samples: 517, CER: 0.5355736705711854\n",
      "lang: cnh, samples: 763, CER: 0.47912514136497514\n",
      "lang: sat, samples: 147, CER: 0.40596308869026315\n",
      "lang: rm-vallader, samples: 462, CER: 0.39101991164453215\n",
      "lang: or, samples: 670, CER: 0.8464969512872611\n",
      "lang: mdf, samples: 104, CER: 0.466300445510711\n",
      "lang: af, samples: 62, CER: 0.45330709681185294\n",
      "lang: ig, samples: 4, CER: 0.6701285963382738\n",
      "lang: sc, samples: 232, CER: 0.44202589637943673\n",
      "lang: tig, samples: 169, CER: 1.0\n",
      "lang: te, samples: 49, CER: 0.8905341862696007\n",
      "lang: ps, samples: 199, CER: 0.488391538686537\n",
      "lang: am, samples: 205, CER: 1.0\n",
      "lang: ast, samples: 162, CER: 0.28144477608953195\n",
      "lang: os, samples: 50, CER: 0.6279852022226734\n",
      "lang: lo, samples: 33, CER: 1.0\n",
      "lang: az, samples: 33, CER: 0.5481673876531203\n",
      "lang: ti, samples: 4, CER: 1.0\n",
      "lang: vot, samples: 6, CER: 0.43847483085183314\n",
      "lang: nhi, samples: 5, CER: 0.6312414467253177\n",
      "lang: yi, samples: 6, CER: 1.0\n",
      "lang: tw, samples: 9, CER: 0.6558037450160406\n",
      "\n",
      "average CER: 0.47777548634450767\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "means = []\n",
    "for k, v in languages.items():\n",
    "    mean = np.mean(v)\n",
    "    if mean >= 1.0:\n",
    "        mean = 1.0\n",
    "    print(f'lang: {k}, samples: {len(v)}, CER: {mean}')\n",
    "    means.append(mean)\n",
    "    \n",
    "print('\\naverage CER:', np.mean(means))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4c50e3a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "115"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(means)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa03258b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3.10",
   "language": "python",
   "name": "python3.10"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
